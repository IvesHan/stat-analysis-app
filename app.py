import streamlit as st
import pandas as pd
import numpy as np
import scipy.stats as stats
import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import matplotlib.pyplot as plt
import seaborn as sns

# --- 0. é¡µé¢é…ç½® ---
st.set_page_config(page_title="Ivesç»Ÿè®¡åˆ†æå·¥å…·", layout="wide")
st.title("Ivesç»Ÿè®¡åˆ†æå·¥å…·")

# --- 1. å®šä¹‰æ•°æ®æ¨¡æ¿ ---
# è¿™äº›æ˜¯å±•ç¤ºç»™ç”¨æˆ·çš„â€œæ —å­â€ï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥åœ¨ä¸Šé¢æ”¹ï¼Œæˆ–è€…è¦†ç›–ç²˜è´´
TEMPLATES = {
    "ä¸¤ç»„æ¯”è¾ƒ (Tæ£€éªŒ/éå‚æ•°)": {
        "desc": "å®½æ ¼å¼ï¼šæ¯ä¸€åˆ—æ˜¯ä¸€ç»„ã€‚é€‚ç”¨ï¼šå®éªŒç»„ vs å¯¹ç…§ç»„ã€‚",
        "data": pd.DataFrame({
            "Control": [10.2, 11.5, 10.8, 12.1, 11.3, 10.9],
            "Treatment": [13.5, 14.2, 15.1, 14.8, 13.9, 15.5]
        })
    },
    "å¤šç»„æ¯”è¾ƒ (ANOVA/éå‚æ•°)": {
        "desc": "å®½æ ¼å¼ï¼šæ¯ä¸€åˆ—æ˜¯ä¸€ç»„ã€‚é€‚ç”¨ï¼š3ç»„åŠä»¥ä¸Šæ¯”è¾ƒã€‚",
        "data": pd.DataFrame({
            "Group_A": [5.1, 5.5, 5.2, 5.8, 5.4],
            "Group_B": [6.2, 6.1, 6.5, 6.3, 6.4],
            "Group_C": [4.5, 4.8, 4.2, 4.6, 4.9],
            "Group_D": [8.1, 8.5, 8.2, 8.6, 8.4]
        })
    },
    "åŒå› ç´ åˆ†æ (Two-Way ANOVA)": {
        "desc": "é•¿æ ¼å¼ï¼šæ ‡å‡†3åˆ—ã€‚åˆ—1=å› ç´ Aï¼Œåˆ—2=å› ç´ Bï¼Œåˆ—3=æ•°å€¼ã€‚",
        "data": pd.DataFrame({
            "Genotype": ["WT"]*4 + ["Mutant"]*4,
            "Drug": ["Vehicle", "Vehicle", "Treated", "Treated"] * 2,
            "Value": [10, 12, 25, 28, 8, 9, 15, 14]
        })
    },
    "åˆ—è”è¡¨ (å¡æ–¹/Fisher)": {
        "desc": "ç»Ÿè®¡è¡¨æ ¼å¼ï¼šç¬¬ä¸€åˆ—æ˜¯è¡Œåï¼Œåé¢æ˜¯æ•°å€¼è®¡æ•°ã€‚",
        "data": pd.DataFrame({
            "Outcome": ["Cured", "Not Cured"],
            "Placebo": [15, 35],
            "Drug_A": [30, 20]
        })
    }
}

# --- 2. ä¾§è¾¹æ ï¼šé€‰æ‹©æ¨¡æ¿ ---
st.sidebar.header("1. åˆ†æç±»å‹é€‰æ‹©")
selected_template = st.sidebar.radio(
    "é€‰æ‹©ä½ çš„æ•°æ®ç±»å‹", 
    list(TEMPLATES.keys())
)

st.sidebar.info(f"ğŸ’¡ **æ ¼å¼è¯´æ˜**ï¼š\n{TEMPLATES[selected_template]['desc']}")

# --- 3. ä¸»ç•Œé¢ï¼šå¯ç¼–è¾‘è¡¨æ ¼ ---
st.subheader("2. æ•°æ®å½•å…¥ (æ”¯æŒä»Excelç›´æ¥å¤åˆ¶ç²˜è´´)")
st.caption("ğŸ‘‡ ç‚¹å‡»è¡¨æ ¼å·¦ä¸Šè§’å¯å…¨é€‰åˆ é™¤ï¼Œç„¶åç²˜è´´ä½ çš„æ•°æ® (Ctrl+V)ã€‚")

# åˆå§‹åŒ– session state ç”¨äºå­˜å‚¨æ•°æ®ï¼Œé˜²æ­¢åˆ·æ–°é‡ç½®
if 'current_df' not in st.session_state or st.session_state.get('last_template') != selected_template:
    st.session_state.current_df = TEMPLATES[selected_template]['data']
    st.session_state.last_template = selected_template

# æ ¸å¿ƒç»„ä»¶ï¼šå¯ç¼–è¾‘è¡¨æ ¼
# num_rows="dynamic" å…è®¸ç”¨æˆ·æ·»åŠ /åˆ é™¤è¡Œ
edited_df = st.data_editor(
    st.session_state.current_df,
    num_rows="dynamic",
    use_container_width=True,
    key=f"editor_{selected_template}" # å…³é”®ï¼šåˆ‡æ¢æ¨¡æ¿æ—¶å¼ºåˆ¶é‡ç»˜è¡¨æ ¼
)

# --- 4. è‡ªåŠ¨åŒ–åˆ†æé€»è¾‘ ---
if edited_df is not None and not edited_df.empty:
    st.divider()
    st.subheader("3. åˆ†ææŠ¥å‘Š")

    # === åˆ†æµå¤„ç†é€»è¾‘ ===
    
    # [åœºæ™¯ A] å®½æ ¼å¼æ¯”è¾ƒ (ä¸¤ç»„ æˆ– å¤šç»„)
    if "ä¸¤ç»„" in selected_template or "å¤šç»„" in selected_template:
        # 1. æ•°æ®æ¸…æ´—ï¼šå®½æ ¼å¼è½¬é•¿æ ¼å¼ (Melt) ä»¥ä¾¿å¤„ç†ä¸åŒé•¿åº¦çš„æ•°æ®
        # åœ¨ data_editor ä¸­ï¼Œç©ºå•å…ƒæ ¼å¯èƒ½æ˜¯ None æˆ– NaN
        cols = edited_df.columns.tolist()
        clean_data = {}
        for c in cols:
            # æå–éç©ºæ•°å€¼
            valid_vals = pd.to_numeric(edited_df[c], errors='coerce').dropna().values
            if len(valid_vals) > 0:
                clean_data[c] = valid_vals
        
        groups = list(clean_data.keys())
        if len(groups) < 2:
            st.warning("âš ï¸ è¯·è‡³å°‘è¾“å…¥ä¸¤åˆ—æœ‰æ•ˆæ•°æ®ã€‚")
            st.stop()
            
        group_vals = [clean_data[g] for g in groups]
        
        # 2. æ£€éªŒæ­£æ€æ€§ä¸æ–¹å·®
        col1, col2 = st.columns(2)
        all_normal = True
        with col1:
            st.write("**æ­£æ€æ€§æ£€éªŒ (Shapiro)**")
            for g, vals in clean_data.items():
                if len(vals) >= 3:
                    s, p = stats.shapiro(vals)
                    is_norm = p > 0.05
                    if not is_norm: all_normal = False
                    st.write(f"- {g}: P={p:.3f} {'âœ…' if is_norm else 'âŒ'}")
                else:
                    st.write(f"- {g}: æ ·æœ¬<3ï¼Œè·³è¿‡")
        
        with col2:
            st.write("**æ–¹å·®é½æ€§ (Levene)**")
            s_lev, p_lev = stats.levene(*group_vals)
            is_homo = p_lev > 0.05
            st.write(f"- æ•´ä½“: P={p_lev:.3f} {'âœ…' if is_homo else 'âŒ'}")
            
        # 3. æ¨èä¸è®¡ç®—
        method_name = ""
        p_val = 1.0
        
        if len(groups) == 2:
            # T-test å®¶æ—
            if all_normal and is_homo:
                method_name = "ç‹¬ç«‹æ ·æœ¬ T æ£€éªŒ"
                res = stats.ttest_ind(group_vals[0], group_vals[1])
                p_val = res.pvalue
            elif all_normal and not is_homo:
                method_name = "Welch's T æ£€éªŒ"
                res = stats.ttest_ind(group_vals[0], group_vals[1], equal_var=False)
                p_val = res.pvalue
            else:
                method_name = "Mann-Whitney U æ£€éªŒ"
                res = stats.mannwhitneyu(group_vals[0], group_vals[1])
                p_val = res.pvalue
        else:
            # ANOVA å®¶æ—
            if all_normal and is_homo:
                method_name = "å•å› ç´ æ–¹å·®åˆ†æ (ANOVA)"
                res = stats.f_oneway(*group_vals)
                p_val = res.pvalue
            else:
                method_name = "Kruskal-Wallis H æ£€éªŒ"
                res = stats.kruskal(*group_vals)
                p_val = res.pvalue
        
        st.info(f"ğŸ’¡ æ¨èæ–¹æ³•ï¼š**{method_name}**")
        st.metric("P-value", f"{p_val:.4e}" if p_val < 0.001 else f"{p_val:.4f}")
        
        # 4. å¯è§†åŒ–
        with st.expander("ğŸ“Š æŸ¥çœ‹å›¾è¡¨ (ç®±çº¿å›¾/QQå›¾)", expanded=True):
            # ä¸ºäº†ç”»å›¾æ–¹ä¾¿ï¼Œæ„å»ºä¸€ä¸ªä¸´æ—¶çš„é•¿æ ¼å¼ DF
            plot_data = []
            for g, vals in clean_data.items():
                for v in vals:
                    plot_data.append({"Group": g, "Value": v})
            df_plot = pd.DataFrame(plot_data)
            
            t1, t2 = st.tabs(["ç®±çº¿å›¾", "QQå›¾"])
            with t1:
                fig, ax = plt.subplots(figsize=(6,4))
                sns.boxplot(data=df_plot, x="Group", y="Value", ax=ax, palette="Set2")
                sns.stripplot(data=df_plot, x="Group", y="Value", color='black', alpha=0.5, ax=ax)
                st.pyplot(fig)
            with t2:
                fig, axes = plt.subplots(1, len(groups), figsize=(4*len(groups), 4))
                if len(groups)==1: axes=[axes]
                for i, g in enumerate(groups):
                    stats.probplot(clean_data[g], dist="norm", plot=axes[i])
                    axes[i].set_title(g)
                st.pyplot(fig)

        # 5. Post-hoc
        if p_val < 0.05 and len(groups) > 2:
            st.write("---")
            st.write("**äº‹åå¤šé‡æ¯”è¾ƒ (Post-hoc)**")
            if "ANOVA" in method_name:
                tukey = pairwise_tukeyhsd(endog=df_plot['Value'], groups=df_plot['Group'])
                st.text(tukey.summary())
            else:
                st.caption("Mann-Whitney U with Bonferroni correction")
                import itertools
                pairs = list(itertools.combinations(groups, 2))
                adj_alpha = 0.05 / len(pairs)
                for g1, g2 in pairs:
                    u, p_pair = stats.mannwhitneyu(clean_data[g1], clean_data[g2])
                    sig = "ğŸ”´æ˜¾è‘—" if p_pair < adj_alpha else "âšª"
                    st.write(f"{g1} vs {g2}: P={p_pair:.4f} {sig}")

    # [åœºæ™¯ B] åŒå› ç´ åˆ†æ (Two-Way ANOVA)
    elif "åŒå› ç´ " in selected_template:
        # 1. Input Validation
        if edited_df.shape[1] < 3:
            st.error("âŒ é”™è¯¯ï¼šåŒå› ç´ åˆ†æéœ€è¦è‡³å°‘3åˆ—æ•°æ® (å› ç´ 1, å› ç´ 2, æ•°å€¼)")
            st.stop()
            
        cols = edited_df.columns
        f1_col, f2_col, val_col = cols[0], cols[1], cols[2]
        
        st.markdown(f"**ğŸ“Š å˜é‡è¯†åˆ«**: Factor A=`{f1_col}`, Factor B=`{f2_col}`, Response=`{val_col}`")

        # 2. Data Cleaning & Preparation
        try:
            df_clean = edited_df.copy()
            # Force numeric conversion, coerce errors to NaN
            df_clean[val_col] = pd.to_numeric(df_clean[val_col], errors='coerce')
            df_clean = df_clean.dropna(subset=[val_col])
            
            # Rename columns to standard internal names to avoid formula errors with spaces/symbols
            df_model = df_clean.rename(columns={f1_col: 'FactorA', f2_col: 'FactorB', val_col: 'Value'})
            
            # Ensure factors are treated as categories
            df_model['FactorA'] = df_model['FactorA'].astype(str)
            df_model['FactorB'] = df_model['FactorB'].astype(str)

        except Exception as e:
            st.error(f"æ•°æ®æ¸…æ´—å¤±è´¥: {e}")
            st.stop()

        # 3. Model Fitting (OLS)
        model = ols('Value ~ C(FactorA) + C(FactorB) + C(FactorA):C(FactorB)', data=df_model).fit()
        anova_table = sm.stats.anova_lm(model, typ=2)

        # 4. Assumption Checks (Crucial for Statistical Rigor)
        with st.expander("ğŸ” å‡è®¾æ£€éªŒè¯Šæ–­ (Assumption Checks)", expanded=True):
            col1, col2 = st.columns(2)
            
            # A. Normality of Residuals
            residuals = model.resid
            stat_shapiro, p_shapiro = stats.shapiro(residuals)
            is_normal = p_shapiro > 0.05
            
            with col1:
                st.write("**æ®‹å·®æ­£æ€æ€§ (Shapiro-Wilk)**")
                st.write(f"P-value = {p_shapiro:.4f}")
                if is_normal:
                    st.success("âœ… æ®‹å·®ç¬¦åˆæ­£æ€åˆ†å¸ƒ")
                else:
                    st.warning("âš ï¸ æ®‹å·®ä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒ (ANOVAå¯¹è½»å¾®åç¦»å…·æœ‰é²æ£’æ€§ï¼Œä½†è¯·è°¨æ…)")
                
                # QQ Plot
                fig_qq, ax_qq = plt.subplots(figsize=(4, 3))
                sm.qqplot(residuals, line='45', fit=True, ax=ax_qq)
                ax_qq.set_title("QQ Plot of Residuals")
                st.pyplot(fig_qq)

            # B. Homogeneity of Variances (Levene)
            # Create a combined group for Levene's test
            df_model['Group_Combo'] = df_model['FactorA'] + "_" + df_model['FactorB']
            groups = [df_model[df_model['Group_Combo'] == g]['Value'].values for g in df_model['Group_Combo'].unique()]
            
            with col2:
                st.write("**æ–¹å·®é½æ€§ (Levene's Test)**")
                if len(groups) > 1:
                    stat_levene, p_levene = stats.levene(*groups)
                    is_homo = p_levene > 0.05
                    st.write(f"P-value = {p_levene:.4f}")
                    if is_homo:
                        st.success("âœ… æ–¹å·®é½æ€§æ»¡è¶³")
                    else:
                        st.warning("âš ï¸ æ–¹å·®ä¸é½ (å¯èƒ½å¢åŠ Type Ié”™è¯¯ç‡)")
                
                # Residuals vs Fitted Plot
                fig_res, ax_res = plt.subplots(figsize=(4, 3))
                sns.scatterplot(x=model.fittedvalues, y=residuals, ax=ax_res)
                ax_res.axhline(0, color='red', linestyle='--')
                ax_res.set_xlabel("Fitted Values")
                ax_res.set_ylabel("Residuals")
                ax_res.set_title("Residuals vs Fitted")
                st.pyplot(fig_res)

        # 5. ANOVA Results Table
        st.subheader("ğŸ“‹ æ–¹å·®åˆ†æè¡¨ (Two-Way ANOVA Results)")
        
        # Rename index for readability
        display_table = anova_table.rename(index={
            'C(FactorA)': f'ä¸»æ•ˆåº”: {f1_col}', 
            'C(FactorB)': f'ä¸»æ•ˆåº”: {f2_col}', 
            'C(FactorA):C(FactorB)': 'äº¤äº’ä½œç”¨ (Interaction)'
        })
        
        # Highlight significant P-values
        def highlight_sig(val):
            color = '#d1e7dd' if val < 0.05 else ''
            return f'background-color: {color}'
        
        st.dataframe(display_table.style.format("{:.4f}").applymap(highlight_sig, subset=['PR(>F)']))

        # 6. Interpretation Logic
        p_interaction = anova_table.loc['C(FactorA):C(FactorB)', 'PR(>F)']
        
        st.info(f"ğŸ’¡ **è§£è¯»æŒ‡å—**:")
        if p_interaction < 0.05:
            st.warning(f"ğŸ”´ **æ£€æµ‹åˆ°æ˜¾è‘—çš„äº¤äº’ä½œç”¨ (P < 0.05)**ã€‚è¿™æ„å‘³ç€ `{f1_col}` å¯¹ç»“æœçš„å½±å“å–å†³äº `{f2_col}` çš„æ°´å¹³ã€‚ä¸èƒ½å•çº¯è§£é‡Šä¸»æ•ˆåº”ï¼Œå¿…é¡»æŸ¥çœ‹äº¤äº’ä½œç”¨å›¾æˆ–è¿›è¡Œç®€å•æ•ˆåº”åˆ†æã€‚")
        else:
            st.success(f"ğŸŸ¢ **æœªæ£€æµ‹åˆ°æ˜¾è‘—äº¤äº’ä½œç”¨**ã€‚å¯ä»¥åˆ†åˆ«ç‹¬ç«‹è§£é‡Šä¸¤ä¸ªä¸»æ•ˆåº”çš„ P å€¼ã€‚")

        # 7. Visualization (Interaction Plot)
        st.subheader("ğŸ“ˆ äº¤äº’ä½œç”¨å›¾ (Interaction Plot)")
        fig, ax = plt.subplots(figsize=(8, 5))
        from statsmodels.graphics.factorplots import interaction_plot
        
        # Using standard matplotlib/statsmodels interaction plot for clarity
        interaction_plot(
            x=df_model['FactorA'], 
            trace=df_model['FactorB'], 
            response=df_model['Value'], 
            colors=['red', 'blue', 'green', 'orange'][:len(df_model['FactorB'].unique())],
            markers=['D', '^', 'o', 's'][:len(df_model['FactorB'].unique())],
            ms=10, ax=ax
        )
        ax.set_xlabel(f1_col)
        ax.set_ylabel(f"Mean of {val_col}")
        ax.legend(title=f2_col)
        ax.grid(True, linestyle='--', alpha=0.5)
        st.pyplot(fig)

        # 8. Post-hoc Analysis (Tukey HSD)
        if p_interaction < 0.05 or anova_table['PR(>F)'].min() < 0.05:
            st.subheader("ğŸ” äº‹åå¤šé‡æ¯”è¾ƒ (Post-hoc Tukey HSD)")
            st.caption("æ¯”è¾ƒæ‰€æœ‰ç»„åˆä¹‹é—´çš„å·®å¼‚ (Factor A Ã— Factor B)")
            
            # Create combination column for pairwise comparison
            df_model['Combination'] = df_model['FactorA'] + " : " + df_model['FactorB']
            
            tukey = pairwise_tukeyhsd(endog=df_model['Value'], groups=df_model['Combination'], alpha=0.05)
            
            # Convert to DataFrame for better display
            tukey_data = pd.DataFrame(data=tukey.summary().data[1:], columns=tukey.summary().data[0])
            
            # Filter only significant results
            sig_results = tukey_data[tukey_data['reject'] == True]
            
            if not sig_results.empty:
                st.write("**æ˜¾è‘—å·®å¼‚çš„ç»„å¯¹:**")
                st.dataframe(sig_results.style.format({'p-adj': '{:.4f}', 'meandiff': '{:.2f}'}))
            else:
                st.write("ANOVA æ˜¾ç¤ºæ˜¾è‘—ï¼Œä½† Tukey æµ‹è¯•æœªå‘ç°å…·ä½“çš„ä¸¤ä¸¤æ˜¾è‘—å·®å¼‚ (å¯èƒ½ç”±äºåŠŸæ•ˆä¸è¶³)ã€‚")
                with st.expander("æŸ¥çœ‹å®Œæ•´æ¯”è¾ƒè¡¨æ ¼"):
                    st.dataframe(tukey_data)
    # [åœºæ™¯ C] åˆ—è”è¡¨ (å¡æ–¹)
    elif "åˆ—è”è¡¨" in selected_template:
        # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯ Row Namesï¼Œåé¢æ˜¯æ•°æ®åˆ—
        row_names = edited_df.iloc[:, 0].astype(str).values
        data_cols = edited_df.columns[1:]
        
        try:
            # æå–çº¯æ•°å€¼çŸ©é˜µ
            observed = edited_df[data_cols].apply(pd.to_numeric, errors='coerce').fillna(0).values
            
            st.write("**è§‚æµ‹é¢‘æ•°è¡¨**")
            st.dataframe(pd.DataFrame(observed, index=row_names, columns=data_cols))
            
            chi2, p, dof, expected = stats.chi2_contingency(observed)
            
            method_name = "Pearson Chi-Square"
            if observed.sum() < 40 or expected.min() < 5:
                if observed.shape == (2,2):
                    method_name = "Fisher's Exact Test"
                    odds, p = stats.fisher_exact(observed)
                else:
                    st.warning("âš ï¸ æ ·æœ¬é‡è¾ƒå°ï¼Œå¡æ–¹ç»“æœå¯èƒ½ä¸å‡†ã€‚")
            
            st.info(f"ğŸ’¡ æ¨èæ–¹æ³•ï¼š**{method_name}**")
            st.metric("P-value", f"{p:.4e}" if p < 0.001 else f"{p:.4f}")
            
        except Exception as e:
            st.error(f"æ•°æ®æ ¼å¼é”™è¯¯ï¼Œè¯·ç¡®ä¿é™¤ç¬¬ä¸€åˆ—å¤–å‡ä¸ºæ•°å­—ã€‚é”™è¯¯ä¿¡æ¯: {e}")

